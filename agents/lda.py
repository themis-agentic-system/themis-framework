"""Implementation of the Legal Docket Analysis (LDA) agent."""

from __future__ import annotations

from collections.abc import Callable, Iterable
from datetime import datetime
from typing import Any

from agents.base import BaseAgent
from agents.tooling import ToolSpec
from tools.document_parser import parse_document_with_llm


class LDAAgent(BaseAgent):
    """Summarise the fact pattern from the incoming matter payload.

    Enhanced with code execution capabilities for:
    - Damages calculations (economic, non-economic, punitive)
    - Statistical analysis of case data
    - Timeline gap analysis
    - Financial modeling for settlement ranges
    """

    REQUIRED_TOOLS = ("document_parser", "timeline_builder")

    def __init__(
        self,
        *,
        tools: Iterable[ToolSpec] | dict[str, Callable[..., Any]] | None = None,
        enable_code_execution: bool = True,
    ) -> None:
        super().__init__(name="lda")
        self.enable_code_execution = enable_code_execution

        default_tools = [
            ToolSpec(
                name="document_parser",
                description="Parse source documents and extract salient facts.",
                fn=_default_document_parser,
                input_schema={
                    "type": "object",
                    "properties": {"documents": {"type": "array"}},
                },
                output_schema={"type": "array"},
            ),
            ToolSpec(
                name="timeline_builder",
                description="Construct a chronological sequence of key events.",
                fn=_default_timeline_builder,
                input_schema={"type": "object"},
                output_schema={"type": "array"},
            ),
            ToolSpec(
                name="damages_calculator",
                description="Calculate damages (economic, non-economic, punitive) using computational analysis.",
                fn=_damages_calculator,
                input_schema={
                    "type": "object",
                    "properties": {
                        "economic_losses": {"type": "object"},
                        "non_economic_factors": {"type": "object"},
                        "punitive_factors": {"type": "object"},
                    },
                },
                output_schema={"type": "object"},
            ),
            ToolSpec(
                name="timeline_analyzer",
                description="Analyze timeline for gaps, patterns, and critical periods using statistical methods.",
                fn=_timeline_analyzer,
                input_schema={
                    "type": "object",
                    "properties": {"timeline": {"type": "array"}},
                },
                output_schema={"type": "object"},
            ),
        ]
        self.register_tools(default_tools)

        if tools:
            if isinstance(tools, dict):
                self.register_tools(list(tools.items()))
            else:
                self.register_tools(tools)

        self.require_tools(self.REQUIRED_TOOLS)

    async def _run(self, matter: dict[str, Any]) -> dict[str, Any]:
        """Autonomously analyze matter and extract structured facts using available tools.

        Claude decides which tools to use and in what order based on the matter data.
        """
        from tools.llm_client import get_llm_client
        import json

        llm = get_llm_client()

        # Define available tools in Anthropic format
        tools = [
            {
                "name": "document_parser",
                "description": "Parse source documents to extract summaries, key facts, dates, and parties. Use this when documents are available.",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "matter": {
                            "type": "object",
                            "description": "Full matter object containing documents and context"
                        }
                    },
                    "required": ["matter"]
                }
            },
            {
                "name": "timeline_builder",
                "description": "Build chronological timeline of events from matter data and parsed documents. Use after parsing documents.",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "matter": {"type": "object", "description": "Matter object with events"},
                        "parsed_documents": {
                            "type": "array",
                            "description": "Parsed documents from document_parser"
                        }
                    },
                    "required": ["matter"]
                }
            },
            {
                "name": "damages_calculator",
                "description": "Calculate total damages including economic, non-economic, and punitive damages. Use when damage data is available.",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "damages_data": {
                            "type": "object",
                            "description": "Damages data with economic_losses, non_economic_factors, etc."
                        }
                    },
                    "required": ["damages_data"]
                }
            },
            {
                "name": "timeline_analyzer",
                "description": "Analyze timeline for patterns, gaps, and critical periods. Use after building timeline.",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "timeline_data": {
                            "type": "object",
                            "description": "Object with timeline array"
                        }
                    },
                    "required": ["timeline_data"]
                }
            }
        ]

        # Map tool names to actual functions
        tool_functions = {
            "document_parser": lambda matter: _default_document_parser(matter),
            "timeline_builder": lambda matter, parsed_documents=None: _default_timeline_builder(matter, parsed_documents),
            "damages_calculator": lambda damages_data: _damages_calculator(damages_data),
            "timeline_analyzer": lambda timeline_data: _timeline_analyzer(timeline_data),
        }

        # Let Claude autonomously decide which tools to use
        system_prompt = """You are LDA (Legal Data Analyst), an expert at extracting and analyzing facts from legal matters.

Your role:
1. Parse all available documents to extract key facts, dates, parties, and summaries
2. Build chronological timelines of events
3. Calculate damages when financial data is available
4. Analyze timelines for patterns, gaps, and critical periods
5. Produce a structured fact summary ready for legal analysis

Use the available tools intelligently based on what data is present in the matter.
After using tools, provide your final analysis as a JSON object with these fields:
- fact_pattern_summary: Array of key facts extracted
- timeline: Array of chronological events
- parties: Array of parties involved
- matter_overview: Summary of the matter
- damages_analysis: (optional) If damages calculated
- timeline_analysis: (optional) If timeline analyzed

Be thorough and extract all relevant factual details."""

        user_prompt = f"""Analyze this legal matter and extract all relevant facts:

MATTER DATA:
{json.dumps(matter, indent=2)}

Use the available tools to:
1. Parse any documents provided
2. Build a timeline of events
3. Calculate damages if financial data is present
4. Analyze the timeline for patterns

Then provide your complete factual analysis."""

        # Claude autonomously uses tools
        result = await llm.generate_with_tools(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            tools=tools,
            tool_functions=tool_functions,
            max_tokens=4096,
        )

        # Parse Claude's final response
        try:
            # Try to extract JSON from response
            response_text = result["result"]
            json_start = response_text.find("{")
            json_end = response_text.rfind("}") + 1
            if json_start != -1 and json_end > json_start:
                facts_payload = json.loads(response_text[json_start:json_end])
            else:
                # Fallback: construct from tool calls
                facts_payload = self._construct_facts_from_tool_calls(result["tool_calls"], matter)
        except (json.JSONDecodeError, KeyError):
            # Fallback to constructing from tool calls
            facts_payload = self._construct_facts_from_tool_calls(result["tool_calls"], matter)

        # Ensure required fields
        if "fact_pattern_summary" not in facts_payload:
            facts_payload["fact_pattern_summary"] = []
        if "timeline" not in facts_payload:
            facts_payload["timeline"] = []
        if "parties" not in facts_payload:
            facts_payload["parties"] = matter.get("parties", [])
        if "matter_overview" not in facts_payload:
            facts_payload["matter_overview"] = matter.get("summary") or matter.get("description") or "Summary unavailable"

        # Track unresolved issues
        unresolved = []
        if not facts_payload.get("fact_pattern_summary"):
            unresolved.append("No facts were successfully extracted from the matter.")
        if not facts_payload.get("parties"):
            unresolved.append("No parties identified in the matter.")

        provenance = {
            "tools_used": [tc["tool"] for tc in result["tool_calls"]],
            "tool_rounds": result["rounds"],
            "autonomous_mode": True,
        }

        return self._build_response(
            core={"facts": facts_payload},
            provenance=provenance,
            unresolved_issues=unresolved,
        )

    def _construct_facts_from_tool_calls(self, tool_calls: list[dict], matter: dict[str, Any]) -> dict[str, Any]:
        """Fallback: construct facts payload from tool call results."""
        facts = {
            "fact_pattern_summary": [],
            "timeline": [],
            "parties": matter.get("parties", []),
            "matter_overview": matter.get("summary") or matter.get("description") or "Summary unavailable"
        }

        for tc in tool_calls:
            if tc["tool"] == "document_parser" and isinstance(tc["result"], list):
                for doc in tc["result"]:
                    facts["fact_pattern_summary"].extend(doc.get("key_facts", []))
            elif tc["tool"] == "timeline_builder" and isinstance(tc["result"], list):
                facts["timeline"] = tc["result"]
            elif tc["tool"] == "damages_calculator" and isinstance(tc["result"], dict):
                facts["damages_analysis"] = tc["result"]
            elif tc["tool"] == "timeline_analyzer" and isinstance(tc["result"], dict):
                facts["timeline_analysis"] = tc["result"]

        return facts


async def _default_document_parser(matter: dict[str, Any]) -> list[dict[str, Any]]:
    """Extract document summaries and key facts using LLM.

    This is now a properly async function that can be awaited.
    """
    documents: Iterable[dict[str, Any]] = matter.get("documents", [])
    parsed: list[dict[str, Any]] = []

    # Extract matter context for better analysis
    matter_context = {
        "summary": matter.get("summary") or matter.get("description"),
        "parties": matter.get("parties", []),
    }

    for document in documents:
        try:
            # Use LLM-powered parser
            parsed_doc = await parse_document_with_llm(document, matter_context)
            parsed.append(parsed_doc)
        except Exception as e:
            # Fallback to basic parsing if LLM fails
            title = document.get("title") or "Untitled Document"
            parsed.append(
                {
                    "document": title,
                    "summary": f"Error parsing document: {e!s}",
                    "key_facts": [],
                    "date": document.get("date"),
                }
            )

    return parsed


def _default_timeline_builder(
    matter: dict[str, Any],
    parsed_documents: list[dict[str, Any]] | None = None,
) -> list[dict[str, Any]]:
    """Build a chronological list of events from the matter payload."""

    events: list[dict[str, Any]] = []
    for raw_event in matter.get("events", []):
        description = raw_event.get("description") or raw_event.get("summary")
        date_str = raw_event.get("date")
        events.append(
            {
                "date": date_str,
                "description": description or "Event description unavailable.",
            }
        )

    if not events and parsed_documents:
        for doc in parsed_documents:
            if doc.get("date"):
                events.append(
                    {
                        "date": doc["date"],
                        "description": f"Document produced: {doc['document']}",
                    }
                )

    def _sort_key(event: dict[str, Any]) -> tuple[int, str]:
        date_str = event.get("date")
        if not date_str:
            return (1, "")
        try:
            parsed_date = datetime.fromisoformat(date_str)
        except (TypeError, ValueError):
            return (0, date_str)
        return (0, parsed_date.isoformat())

    events.sort(key=_sort_key)
    return events


async def _damages_calculator(damages_data: dict[str, Any]) -> dict[str, Any]:
    """Calculate total damages using computational analysis.

    This tool can leverage Claude's code execution capability when available
    for accurate financial calculations, projections, and statistical analysis.

    Args:
        damages_data: Dictionary containing:
            - economic_losses: Dict of economic damages (medical, lost wages, etc.)
            - non_economic_factors: Dict of non-economic factors (pain/suffering, etc.)
            - punitive_factors: Dict of punitive damage factors (if applicable)

    Returns:
        Dictionary with calculated totals, breakdowns, and analysis.
    """
    from tools.llm_client import get_llm_client

    client = get_llm_client()

    # Prepare prompt for calculation
    prompt = f"""Calculate total damages from the following data:

Economic Losses: {damages_data.get('economic_losses', {})}
Non-Economic Factors: {damages_data.get('non_economic_factors', {})}
Punitive Factors: {damages_data.get('punitive_factors', {})}

Provide a detailed breakdown including:
1. Total economic damages (sum of all economic losses)
2. Non-economic damages estimate (based on factors provided)
3. Punitive damages (if applicable)
4. Grand total with confidence interval
5. Settlement range recommendation (60-80% of total for settlement strategy)

Return as JSON with the structure:
{{
    "economic_total": float,
    "non_economic_estimate": float,
    "punitive_total": float,
    "grand_total": float,
    "confidence_level": str,
    "settlement_range": {{"min": float, "max": float}},
    "breakdown": dict
}}
"""

    try:
        result = await client.generate_structured(
            system_prompt="You are a legal damages calculator. Perform accurate financial calculations.",
            user_prompt=prompt,
            response_format={
                "economic_total": 0.0,
                "non_economic_estimate": 0.0,
                "punitive_total": 0.0,
                "grand_total": 0.0,
                "confidence_level": "medium",
                "settlement_range": {"min": 0.0, "max": 0.0},
                "breakdown": {},
            },
        )
        return result
    except Exception as e:
        # Fallback to simple summation
        economic = damages_data.get("economic_losses", {})
        economic_total = sum(float(v) for v in economic.values() if isinstance(v, (int, float)))

        return {
            "economic_total": economic_total,
            "non_economic_estimate": 0.0,
            "punitive_total": 0.0,
            "grand_total": economic_total,
            "confidence_level": "low",
            "settlement_range": {"min": economic_total * 0.6, "max": economic_total * 0.8},
            "breakdown": {"economic": economic},
            "error": str(e),
        }


async def _timeline_analyzer(timeline_data: dict[str, Any]) -> dict[str, Any]:
    """Analyze timeline for gaps, patterns, and critical periods.

    Uses computational analysis to identify:
    - Timeline gaps (periods with no recorded events)
    - Event clustering (periods of high activity)
    - Critical dates and deadlines
    - Statistical patterns in event distribution

    Args:
        timeline_data: Dictionary containing 'timeline' list of events.

    Returns:
        Dictionary with analysis results.
    """
    from tools.llm_client import get_llm_client

    client = get_llm_client()
    timeline = timeline_data.get("timeline", [])

    if not timeline:
        return {"gaps": [], "clusters": [], "critical_periods": [], "summary": "No timeline data available"}

    prompt = f"""Analyze the following timeline for legal case planning:

Timeline Events:
{timeline}

Provide analysis including:
1. Timeline gaps (periods >30 days between events)
2. Event clusters (3+ events within 14 days)
3. Critical periods (high activity indicating important case developments)
4. Duration from first to last event
5. Average time between events
6. Recommendations for additional fact development

Return as JSON with structure:
{{
    "duration_days": int,
    "total_events": int,
    "gaps": [{{"start_date": str, "end_date": str, "days": int}}],
    "clusters": [{{"period": str, "event_count": int, "significance": str}}],
    "critical_periods": [str],
    "average_gap_days": float,
    "recommendations": [str]
}}
"""

    try:
        result = await client.generate_structured(
            system_prompt="You are a legal timeline analyst. Analyze event sequences for patterns and gaps.",
            user_prompt=prompt,
            response_format={
                "duration_days": 0,
                "total_events": 0,
                "gaps": [],
                "clusters": [],
                "critical_periods": [],
                "average_gap_days": 0.0,
                "recommendations": [],
            },
        )
        return result
    except Exception as e:
        # Fallback to basic analysis
        valid_dates = []
        for event in timeline:
            date_str = event.get("date")
            if date_str:
                try:
                    valid_dates.append(datetime.fromisoformat(date_str))
                except (TypeError, ValueError):
                    pass

        duration = 0
        if len(valid_dates) >= 2:
            valid_dates.sort()
            duration = (valid_dates[-1] - valid_dates[0]).days

        return {
            "duration_days": duration,
            "total_events": len(timeline),
            "gaps": [],
            "clusters": [],
            "critical_periods": [],
            "average_gap_days": duration / max(len(valid_dates) - 1, 1) if valid_dates else 0,
            "recommendations": ["Manual timeline review recommended"],
            "error": str(e),
        }
